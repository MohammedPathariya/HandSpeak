{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88e21a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedpathariya/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744304659.546836 6340516 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1744304659.572294 6340761 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744304659.579820 6340761 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-04-10 13:04:19.899 python[94141:6340516] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to capture. Press keys:\n",
      "1 = hello\n",
      "2 = goodbye\n",
      "3 = please\n",
      "4 = thank_you\n",
      "5 = yes\n",
      "6 = no\n",
      "Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744304661.353050 6340756 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2025-04-10 13:04:21.757 python[94141:6340516] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-10 13:04:21.757 python[94141:6340516] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved please → captured_data/images/please/please_20250410_130525_369566.jpg, captured_data/landmarks/please/please_20250410_130525_369566.npy\n",
      "Saved please → captured_data/images/please/please_20250410_130526_659234.jpg, captured_data/landmarks/please/please_20250410_130526_659234.npy\n",
      "Saved please → captured_data/images/please/please_20250410_130527_958850.jpg, captured_data/landmarks/please/please_20250410_130527_958850.npy\n",
      "Saved please → captured_data/images/please/please_20250410_130529_124361.jpg, captured_data/landmarks/please/please_20250410_130529_124361.npy\n",
      "Saved please → captured_data/images/please/please_20250410_130530_191839.jpg, captured_data/landmarks/please/please_20250410_130530_191839.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from datetime import datetime\n",
    "\n",
    "# === [1] Configurations === #\n",
    "labels_map = {\n",
    "    '1': 'hello',\n",
    "    '2': 'goodbye',\n",
    "    '3': 'please',\n",
    "    '4': 'thank_you',\n",
    "    '5': 'yes',\n",
    "    '6': 'no'\n",
    "}\n",
    "output_dir = \"captured_data\"\n",
    "images_dir = os.path.join(output_dir, \"images\")\n",
    "landmarks_dir = os.path.join(output_dir, \"landmarks\")\n",
    "\n",
    "# Create necessary folders\n",
    "for label in labels_map.values():\n",
    "    os.makedirs(os.path.join(images_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(landmarks_dir, label), exist_ok=True)\n",
    "\n",
    "# === [2] Initialize MediaPipe and Webcam === #\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=1,\n",
    "                       min_detection_confidence=0.7,\n",
    "                       min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "print(\"Ready to capture. Press keys:\")\n",
    "for key, label in labels_map.items():\n",
    "    print(f\"{key} = {label}\")\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "# === [3] Main Loop === #\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # Draw landmarks if detected\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display instructions\n",
    "    cv2.putText(frame, \"Press 1-6 to label and save, q to quit\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Sign Capture\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    key_char = chr(key)\n",
    "\n",
    "    # Handle quit\n",
    "    if key_char == 'q':\n",
    "        break\n",
    "\n",
    "    # If valid label key is pressed\n",
    "    if key_char in labels_map and result.multi_hand_landmarks:\n",
    "        label = labels_map[key_char]\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "\n",
    "        # Save image\n",
    "        img_path = os.path.join(images_dir, label, f\"{label}_{timestamp}.jpg\")\n",
    "        cv2.imwrite(img_path, frame)\n",
    "\n",
    "        # Save landmarks\n",
    "        hand_landmark = result.multi_hand_landmarks[0]\n",
    "        landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmark.landmark])\n",
    "        lm_path = os.path.join(landmarks_dir, label, f\"{label}_{timestamp}.npy\")\n",
    "        np.save(lm_path, landmarks)\n",
    "\n",
    "        print(f\"Saved {label} → {img_path}, {lm_path}\")\n",
    "\n",
    "# === [4] Cleanup === #\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264be175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86655f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7e0f09",
   "metadata": {},
   "source": [
    "First code not working for 3, 4 and 5 (thank you, yes, no) and also some problems for q (quit).\n",
    "\n",
    "In the initial version of the code, the keypress detection was implemented using `cv2.waitKey()` in combination with `chr(key)` to convert the detected key code into a character. While this approach worked correctly for keys like '1', '2', and '3', it caused issues for other keys such as '4', '5', '6', and even 'q' on certain systems, particularly macOS. This is because the `cv2.waitKey()` function behaves differently across platforms, and the values returned for certain keys may not directly map to their corresponding character using `chr(key)`. As a result, pressing these keys did not trigger the expected conditions in the code, leading to the failure in capturing images and landmark data for the last three signs.\n",
    "\n",
    "To resolve this issue and make the key detection platform-independent and reliable, the updated code uses `ord()` to directly compare the detected key with its ASCII value. By using conditions like `if key == ord('1')` or `if key == ord('q')`, the code ensures that the correct label is assigned or the program exits cleanly regardless of the operating system or terminal behavior. This modification provides a more robust and consistent way to handle keyboard inputs in OpenCV, making the code reliable across different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31677066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50889c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c31faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedpathariya/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744305597.653992 6352851 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1744305597.738327 6354688 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744305597.750354 6354688 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-04-10 13:19:59.920 python[94509:6352851] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to capture. Press keys:\n",
      "1 = hello\n",
      "2 = goodbye\n",
      "3 = please\n",
      "4 = thank_you\n",
      "5 = yes\n",
      "6 = no\n",
      "Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 13:20:01.726 python[94509:6352851] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-10 13:20:01.727 python[94509:6352851] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "W0000 00:00:1744305604.100228 6354689 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132054_201415.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132054_201415.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132055_092697.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132055_092697.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132056_025295.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132056_025295.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132056_925161.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132056_925161.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132057_990932.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132057_990932.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132059_290901.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132059_290901.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132100_423558.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132100_423558.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132101_456238.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132101_456238.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132102_489318.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132102_489318.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132103_521499.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132103_521499.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132152_002133.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132152_002133.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132152_902170.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132152_902170.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132153_668568.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132153_668568.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132154_500713.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132154_500713.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132155_300624.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132155_300624.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132156_299874.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132156_299874.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132157_233572.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132157_233572.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132158_233078.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132158_233078.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132159_098679.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132159_098679.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132200_165135.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132200_165135.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132202_231707.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132202_231707.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132203_130661.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132203_130661.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132204_363961.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132204_363961.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132205_664021.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132205_664021.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132207_762710.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132207_762710.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132212_448372.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132212_448372.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132213_331318.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132213_331318.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132214_526738.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132214_526738.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132215_659938.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132215_659938.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132218_861966.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132218_861966.npy\n",
      "[Captured] Label: thank_you → Image: captured_data/images/thank_you/thank_you_20250410_132229_087053.jpg, Landmarks: captured_data/landmarks/thank_you/thank_you_20250410_132229_087053.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132256_510086.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132256_510086.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132257_409545.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132257_409545.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132258_242681.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132258_242681.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132259_075271.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132259_075271.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132300_074017.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132300_074017.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132300_907558.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132300_907558.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132301_907328.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132301_907328.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132302_974022.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132302_974022.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132303_806038.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132303_806038.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132304_772963.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132304_772963.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132311_476622.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132311_476622.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132312_241711.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132312_241711.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132313_159858.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132313_159858.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132313_975049.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132313_975049.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132315_074446.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132315_074446.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132315_908047.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132315_908047.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132316_835851.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132316_835851.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132318_431855.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132318_431855.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132319_299686.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132319_299686.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132320_133232.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132320_133232.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132321_265908.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132321_265908.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132322_199195.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132322_199195.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132324_197541.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132324_197541.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132325_030384.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132325_030384.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132326_096481.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132326_096481.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132330_895008.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132330_895008.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132331_562011.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132331_562011.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132332_394403.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132332_394403.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132333_260951.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132333_260951.npy\n",
      "[Captured] Label: yes → Image: captured_data/images/yes/yes_20250410_132334_461245.jpg, Landmarks: captured_data/landmarks/yes/yes_20250410_132334_461245.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132343_323948.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132343_323948.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132344_123695.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132344_123695.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132344_989397.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132344_989397.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132345_855796.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132345_855796.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132346_654780.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132346_654780.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132347_588582.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132347_588582.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132348_487215.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132348_487215.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132349_388189.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132349_388189.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132350_320350.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132350_320350.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132352_219536.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132352_219536.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132353_452884.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132353_452884.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132354_885824.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132354_885824.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132356_117886.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132356_117886.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132357_750267.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132357_750267.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132359_848777.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132359_848777.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132400_781866.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132400_781866.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132407_446584.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132407_446584.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132408_812230.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132408_812230.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132410_078421.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132410_078421.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132411_144422.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132411_144422.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132412_210731.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132412_210731.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132413_410471.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132413_410471.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132414_377317.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132414_377317.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132415_408975.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132415_408975.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132416_475430.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132416_475430.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132417_509633.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132417_509633.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132418_575920.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132418_575920.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132419_642116.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132419_642116.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132420_807530.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132420_807530.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132421_874006.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132421_874006.npy\n",
      "[Captured] Label: no → Image: captured_data/images/no/no_20250410_132422_939962.jpg, Landmarks: captured_data/landmarks/no/no_20250410_132422_939962.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from datetime import datetime\n",
    "\n",
    "# === [1] Configurations === #\n",
    "labels_map = {\n",
    "    ord('1'): 'hello',\n",
    "    ord('2'): 'goodbye',\n",
    "    ord('3'): 'please',\n",
    "    ord('4'): 'thank_you',\n",
    "    ord('5'): 'yes',\n",
    "    ord('6'): 'no'\n",
    "}\n",
    "\n",
    "output_dir = \"captured_data\"\n",
    "images_dir = os.path.join(output_dir, \"images\")\n",
    "landmarks_dir = os.path.join(output_dir, \"landmarks\")\n",
    "\n",
    "# Create folders for each label\n",
    "for label in labels_map.values():\n",
    "    os.makedirs(os.path.join(images_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(landmarks_dir, label), exist_ok=True)\n",
    "\n",
    "# === [2] Initialize MediaPipe and Webcam === #\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=1,\n",
    "                       min_detection_confidence=0.7,\n",
    "                       min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "print(\"Ready to capture. Press keys:\")\n",
    "for k, v in labels_map.items():\n",
    "    print(f\"{chr(k)} = {v}\")\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "# === [3] Main Loop === #\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # Draw landmarks if detected\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display instructions on screen\n",
    "    cv2.putText(frame, \"Press 1-6 to label & save | Press 'q' to quit\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Sign Capture\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    if key in labels_map and result.multi_hand_landmarks:\n",
    "        label = labels_map[key]\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "\n",
    "        # Save image\n",
    "        img_path = os.path.join(images_dir, label, f\"{label}_{timestamp}.jpg\")\n",
    "        cv2.imwrite(img_path, frame)\n",
    "\n",
    "        # Save landmarks\n",
    "        landmarks = np.array([[lm.x, lm.y, lm.z] for lm in result.multi_hand_landmarks[0].landmark])\n",
    "        lm_path = os.path.join(landmarks_dir, label, f\"{label}_{timestamp}.npy\")\n",
    "        np.save(lm_path, landmarks)\n",
    "\n",
    "        print(f\"[Captured] Label: {label} → Image: {img_path}, Landmarks: {lm_path}\")\n",
    "\n",
    "# === [4] Cleanup === #\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97487d1a",
   "metadata": {},
   "source": [
    "### Explanation of Data Collection using Webcam and Saving Landmark Data\n",
    "\n",
    "In the first part of the project, a Python script was developed using OpenCV and MediaPipe to collect sign language data through the webcam. The system was designed to detect the user's hand in real-time, identify 21 key landmarks on the hand, and draw connections between these points for visualization.\n",
    "\n",
    "When a specific key (1 to 6) was pressed, corresponding to a particular sign (hello, goodbye, please, thank_you, yes, no), the script captured the current frame and saved two things:  \n",
    "1. The image with the hand visible — for reference.  \n",
    "2. The landmark coordinates extracted by MediaPipe — saved as a `.npy` file for later use in machine learning.\n",
    "\n",
    "This process helped in creating a labeled dataset of hand signs, where both visual data and numerical landmark data were stored and organized systematically into folders based on their respective classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f889b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacde846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
